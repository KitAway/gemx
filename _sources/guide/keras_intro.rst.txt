GEMX based Keras MLP Acceleration Example
=============================================

Keras is python based machine learning framework. It provides high level
neural network APIs. It is written in Python and can run on top of other
low level neural network frameworks for numerical computations like
TensorFlow, Theano, and CNTK etc. Keras supports neural as well as
recurrent networks and hybrid solution is also possible. It is assumed
to be very user friendly and allows for easy and rapid prototyping and
experimentation through modular and extensible approach.

This example provided with GEMX repository is based on a neural network
which is 3 layers deep. The inference part is accelerated using FPGA
based hardware engines. The choice of three different engines is given
to allow the trade-off between performance and hardware resource
utilization. Application is launched with different arguments as
follows:

.. code-block:: bash

  python mlp.py --data data_file.csv --model hdf5.h5 --xclbin gemx_engine.xclbin --cfg config_info.dat --gemxlib libgemxhost.so --engine fcn

Multiple command line arguments are passed which provide path to data to
be used for prediction, network model stored in hdf5 format, Xilinx FPGA
configuration binary which contains FPGA acceleration kernel and
configures FPGA on the fly, .dat file which provides GEMX engine
configuration parameters, --engine makes the selection of FPGA engine to
be used and finally .so files which is the path to the shared library
written in C++ and accessed in Python application using a C type python
wrapper.

The application starts by parsing these command line arguments:

.. code-block:: python

  parser.add_argument('--cfg', required = True, help='file describing properties of .xclbin')
  parser.add_argument('--gemxlib', required = True, help='file path to GEMX host code shared library')
  parser.add_argument('--engine', default = 'fcn', choices=['fcn','spmv','uspmv'], help='choose fcn, spmv, uspmv engine')
  args = parser.parse_args()

After parsing argument application parses FPGA engine configuration file
and creates a handle to FPGA device with appropriate arguments and
xclbin.

.. code-block:: python

  if args.engine == 'fcn':
    gemx.createFCNHandle( args, xclbin_prop )
  elif args.engine == 'uspmv':
    gemx.createUSPMVHandle( args, xclbin_prop )
  else:
    gemx.createSPMVHandle( args, xclbin_prop )

The input data and labels are loaded from a .csv file which stores
data as comma separated list. Input data is labeled with class numbers.
The application loads this data to a dictionary and encodes labels using
one-hot encoding technique.

.. code-block:: python

  train_fd = pd.read_csv(args.data)
  IDcol = 'Run'
  target = 'Class'
  predictors = [x for x in train_fd.columns if x not in [target, IDcol]]
  encoder = LabelEncoder()
  encoder.fit(train_fd[target])
  encoded_Y = encoder.transform(train_fd[target])
  train_y = np_utils.to_categorical(encoded_Y)


The application is used to perform multi-level classification using
3-level deep neural network, with fully connected layers. The network is
trained offline and trained model is stored in hdf5 format. All the
layers are dense and final layer uses softmax classifier enabling the
calculation of score or confidence for each prediction. The softmax
calculation are done using CPU. The first layer consists of 100 neurons
and the 2\ :sup:`nd` layer is composed of 25 neurons, both these layers
use “relu” type activation. The input data used for classification
consist of 5 classes with 128 features per input and hence the final
layer is composed of 5 Neuron with softmax activation.

.. code-block:: python

  model = Sequential()
  model.add(Dense(100, input_dim=in_dims, activation='relu', name='d1'))
  model.add(Dense(25, activation='relu', name='d2'))
  model.add(Dense(num_classes, activation='softmax', name='d3'))

The actual function which calls for prediction on input data is
predit_fpga or predict_spmv or predict_uspmv depending on the user
engine choice made by passing command line argument.

.. code-block:: python

  if args.engine == 'fcn':
    fpga_out = predict_fpga( args.model, train_fd[predictors], len(train_fd[target].unique()), xclbin_prop)
  elif args.engine == 'uspmv':
    fpga_out = predict_uspmv_fpga( args.model, train_fd[predictors], len(train_fd[target].unique()), xclbin_prop)
  else:
    fpga_out = predict_spmv_fpga( args.model, train_fd[predictors], len(train_fd[target].unique()), xclbin_prop)

This function call will build Keras sequential model using dense layers
and weight matrices loaded from hdf5 file. For predict_fpga case where
integer types are used to represent and process data, model weights and
biases are quantized using scaling constants. These constants are
determined offline by performing range and max-min analysis on the data.
With given 3-layer network application can make prediction in 5ms using
FCN engine which is based on dense matrix multiplication and with SPMV
engine which is based on sparse matrix multiplication it takes 138ms for
prediction and uses 10x less DSP48 resources on FPGA. USPMV is more
optimized implementation for sparse matrix multiplication engine which
takes 4ms for the prediction and it uses 4x less DSPs and 8x less BRAMs
when compared to original FCN engine, but uses more URAMs. The table
below gives more details.

============= ======================== ======== ========= ========= ======== =======
**Engine**    **Prediction time (ms)** **DSPs** **BRAMs** **URAMs** **LUTs** **FFs**
============= ======================== ======== ========= ========= ======== =======
FCN(int16)    5                        1166     321       0         69044    211631                                                                     
SPMV          138                      108      571       8         59381    101391
3-stage USPMV 4                        304      41        96        231194   271055
CPU           20                       n/a      n/a       n/a       n/a      n/a
============= ======================== ======== ========= ========= ======== =======
